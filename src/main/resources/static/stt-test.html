<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>ìŒì„± ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸</title>
</head>
<body>
<h2>ğŸ¤ í†µí™” ê¸°ëŠ¥</h2>
<button id="startCallBtn">ğŸ“ í†µí™” ì‹œì‘</button>
<button id="recordBtn" disabled>ğŸ™ï¸ ë…¹ìŒ</button>
<button id="endCallBtn" disabled>ğŸ“´ í†µí™” ì¢…ë£Œ</button>
<p id="status">ìƒíƒœ: ëŒ€ê¸° ì¤‘</p>
<p id="transcriptText">ğŸ“ ì „ì‚¬ ê²°ê³¼: ì—†ìŒ</p>

<script>
    const startCallBtn = document.getElementById('startCallBtn');
    const recordBtn = document.getElementById('recordBtn');
    const endCallBtn = document.getElementById('endCallBtn');
    const statusText = document.getElementById('status');
    const transcriptText = document.getElementById('transcriptText');

    let socket;
    let audioContext;
    let processor;
    let input;
    let recording = false;
    let recordStartTime = null;

    const wsUrl = `ws://${location.hostname}:8080/ws/speech`;

    async function initAudioProcessing() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioContext = new AudioContext({ sampleRate: 16000 });
            input = audioContext.createMediaStreamSource(stream);
            processor = audioContext.createScriptProcessor(4096, 1, 1);

            processor.onaudioprocess = (e) => {
                if (!recording || !socket || socket.readyState !== WebSocket.OPEN) return;

                const audioData = e.inputBuffer.getChannelData(0); // Float32Array
                const buffer = new ArrayBuffer(audioData.length * 2); // 16bit = 2 bytes
                const view = new DataView(buffer);

                for (let i = 0; i < audioData.length; i++) {
                    let sample = Math.max(-1, Math.min(1, audioData[i])); // clamp between [-1, 1]
                    sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF; // convert to 16-bit PCM
                    view.setInt16(i * 2, sample, true); // true = littleEndian
                }

                socket.send(buffer); // send LINEAR16 encoded buffer
            };

            input.connect(processor);
            processor.connect(audioContext.destination);
        } catch (err) {
            statusText.textContent = 'âŒ ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨';
            console.error("ğŸ¤ ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨", err);
        }
    }

    function startCall() {
        socket = new WebSocket(wsUrl);

        socket.onopen = async () => {
            statusText.textContent = 'ìƒíƒœ: í†µí™” ì—°ê²°ë¨';
            console.log("âœ… WebSocket ì—°ê²°ë¨");

            await initAudioProcessing();

            recordBtn.disabled = false;
            endCallBtn.disabled = false;
            startCallBtn.disabled = true;
        };

        socket.onmessage = (event) => {
            console.log("ğŸ“¥ ì„œë²„ ì‘ë‹µ:", event.data);
            try {
                const msg = event.data;
                transcriptText.textContent = "ğŸ“ ì „ì‚¬ ê²°ê³¼: " + msg;
            } catch (e) {
                console.log("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: ", e);
            }
        };

        socket.onerror = (e) => {
            console.error("âŒ WebSocket ì˜¤ë¥˜", e);
            statusText.textContent = 'âŒ WebSocket ì˜¤ë¥˜ ë°œìƒ';
        };

        socket.onclose = () => {
            console.log("ğŸ”Œ WebSocket ì¢…ë£Œë¨");
        };
    }

    function startRecording() {
        if (socket && socket.readyState === WebSocket.OPEN) {
            socket.send("start");
            recording = true;
            recordStartTime = Date.now(); // ë…¹ìŒ ì‹œì‘ ì‹œê°„ ê¸°ë¡
            statusText.textContent = 'ìƒíƒœ: ë…¹ìŒ ì¤‘...';
            console.log("ğŸ™ï¸ ë…¹ìŒ ì‹œì‘");
        }
    }

    function stopRecording() {
        if (!recording) return;
        recording = false;
        const duration = Date.now() - recordStartTime;
        recordStartTime = null;
        statusText.textContent = 'ìƒíƒœ: í†µí™” ì—°ê²°ë¨';
        console.log("ğŸ›‘ ë…¹ìŒ ì •ì§€");

        if (duration >= 1000) {
            if (socket && socket.readyState === WebSocket.OPEN) {
                socket.send("stop"); // ì„œë²„ì—ê²Œ ì „ì‚¬ ìš”ì²­
                console.log("ğŸ“¤ stop ë©”ì‹œì§€ ì „ì†¡ë¨");
            }
        } else {
            console.warn("â±ï¸ ë…¹ìŒ ì‹œê°„ 1ì´ˆ ë¯¸ë§Œìœ¼ë¡œ ì „ì‚¬ ìš”ì²­ ìƒëµ");
        }
    }

    function endCall() {
        stopRecording();

        statusText.textContent = 'ìƒíƒœ: ëŒ€ê¸° ì¤‘';
        transcriptText.textContent = "ğŸ“ ì „ì‚¬ ê²°ê³¼: ì—†ìŒ";

        if (processor) {
            processor.disconnect();
            processor = null;
        }
        if (input) {
            input.disconnect();
            input = null;
        }
        if (audioContext) {
            audioContext.close();
            audioContext = null;
        }

        if (socket && socket.readyState === WebSocket.OPEN) {
            socket.close();
        }
        socket = null;

        recordBtn.disabled = true;
        endCallBtn.disabled = true;
        startCallBtn.disabled = false;

        console.log("ğŸ“´ í†µí™” ì¢…ë£Œ");
    }

    startCallBtn.addEventListener('click', startCall);
    recordBtn.addEventListener('mousedown', startRecording);
    recordBtn.addEventListener('mouseup', stopRecording);
    recordBtn.addEventListener('touchstart', (e) => {
        e.preventDefault();
        startRecording();
    });
    recordBtn.addEventListener('touchend', (e) => {
        e.preventDefault();
        stopRecording();
    });
    endCallBtn.addEventListener('click', endCall);
</script>
</body>
</html>