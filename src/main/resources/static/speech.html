<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>ìŒì„± ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸</title>
</head>
<body>
<h2>ğŸ¤ í†µí™” ê¸°ëŠ¥</h2>
<button id="startCallBtn">ğŸ“ í†µí™” ì‹œì‘</button>
<button id="recordBtn" disabled>ğŸ™ï¸ ë…¹ìŒ</button>
<button id="endCallBtn" disabled>ğŸ“´ í†µí™” ì¢…ë£Œ</button>
<p id="status">ìƒíƒœ: ëŒ€ê¸° ì¤‘</p>
<p id="transcriptText">ğŸ“ ì „ì‚¬ ê²°ê³¼: ì—†ìŒ</p>

<script>
    const SAMPLE_RATE = 24000;
    const wsUrl = `wss://api.charactalk.site/ws/speech`;
    // const wsUrl = `ws://localhost:8080/ws/speech`;

    const $ = (id) => document.getElementById(id);
    const startCallBtn = $('startCallBtn');
    const recordBtn = $('recordBtn');
    const endCallBtn = $('endCallBtn');
    const statusText = $('status');
    const transcriptText = $('transcriptText');

    let socket, audioContext, processor, input;
    let recording = false;
    let recordStartTime = null;
    let audioQueue = [];
    let isPlaying = false;

    // ğŸ§ ì˜¤ë””ì˜¤ ì²˜ë¦¬
    async function initAudioProcessing() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioContext = new AudioContext({ sampleRate: SAMPLE_RATE });
            input = audioContext.createMediaStreamSource(stream);

            processor = audioContext.createScriptProcessor(4096, 1, 1);
            processor.onaudioprocess = (e) => {
                if (!recording || !socket || socket.readyState !== WebSocket.OPEN) return;

                const floatData = e.inputBuffer.getChannelData(0);
                const int16Buffer = float32ToLinear16(floatData);
                socket.send(int16Buffer);
            };

            input.connect(processor);
            processor.connect(audioContext.destination);
        } catch (err) {
            updateStatus('âŒ ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨');
            console.error("ğŸ¤ ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨", err);
        }
    }

    function float32ToLinear16(floatData) {
        const buffer = new ArrayBuffer(floatData.length * 2);
        const view = new DataView(buffer);
        for (let i = 0; i < floatData.length; i++) {
            let sample = Math.max(-1, Math.min(1, floatData[i]));
            sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
            view.setInt16(i * 2, sample, true);
        }
        return buffer;
    }

    function decodeLinear16ToAudioBuffer(buffer, audioCtx) {
        const view = new DataView(buffer);
        const len = buffer.byteLength / 2;
        const audioBuffer = audioCtx.createBuffer(1, len, SAMPLE_RATE);
        const data = audioBuffer.getChannelData(0);
        for (let i = 0; i < len; i++) {
            data[i] = view.getInt16(i * 2, true) / 32768.0;
        }
        return audioBuffer;
    }

    function playBuffer(audioCtx, buffer) {
        return new Promise(resolve => {
            const source = audioCtx.createBufferSource();
            source.buffer = buffer;
            source.connect(audioCtx.destination);
            source.onended = resolve;
            source.start();
        });
    }

    async function playQueue() {
        if (audioQueue.length === 0) {
            isPlaying = false;
            return;
        }
        isPlaying = true;
        const buffer = audioQueue.shift();
        await playBuffer(audioContext, buffer);
        await playQueue();
    }

    // ğŸ“¡ WebSocket ì—°ê²°
    function startCall() {
        socket = new WebSocket(wsUrl);
        socket.binaryType = "arraybuffer";

        socket.onopen = async () => {
            updateStatus('ìƒíƒœ: í†µí™” ì—°ê²°ë¨');
            console.log("âœ… WebSocket ì—°ê²°ë¨");

            await initAudioProcessing();

            toggleButtons({ start: false, record: true, end: true });
        };

        socket.onmessage = async (event) => {
            const audioBuffer = decodeLinear16ToAudioBuffer(event.data, audioContext);
            audioQueue.push(audioBuffer);
            if (!isPlaying) await playQueue();
        };

        socket.onerror = (e) => {
            console.error("âŒ WebSocket ì˜¤ë¥˜", e);
            updateStatus('âŒ WebSocket ì˜¤ë¥˜ ë°œìƒ');
        };

        socket.onclose = () => {
            console.log("ğŸ”Œ WebSocket ì¢…ë£Œë¨");
        };
    }

    // ğŸ™ï¸ ë…¹ìŒ ì œì–´
    function startRecording() {
        if (socket?.readyState === WebSocket.OPEN) {
            socket.send("start");
            recording = true;
            recordStartTime = Date.now();
            updateStatus('ìƒíƒœ: ë…¹ìŒ ì¤‘...');
            console.log("ğŸ™ï¸ ë…¹ìŒ ì‹œì‘");
        }
    }

    function stopRecording() {
        if (!recording) return;
        recording = false;

        const duration = Date.now() - recordStartTime;
        recordStartTime = null;
        updateStatus('ìƒíƒœ: í†µí™” ì—°ê²°ë¨');
        console.log("ğŸ›‘ ë…¹ìŒ ì •ì§€");

        if (duration >= 500 && socket?.readyState === WebSocket.OPEN) {
            socket.send("stop");
            console.log("ğŸ“¤ stop ë©”ì‹œì§€ ì „ì†¡ë¨");
        } else {
            console.warn("â±ï¸ ë…¹ìŒ ì‹œê°„ 0.5ì´ˆ ë¯¸ë§Œ â†’ ì „ì‚¬ ìƒëµ");
        }
    }

    // ğŸ“´ í†µí™” ì¢…ë£Œ
    function endCall() {
        stopRecording();
        cleanupAudio();
        cleanupSocket();

        toggleButtons({ start: true, record: false, end: false });
        updateStatus('ìƒíƒœ: ëŒ€ê¸° ì¤‘');
        transcriptText.textContent = "ğŸ“ ì „ì‚¬ ê²°ê³¼: ì—†ìŒ";

        console.log("ğŸ“´ í†µí™” ì¢…ë£Œ");
    }

    // ğŸ”§ ì •ë¦¬
    function cleanupAudio() {
        processor?.disconnect();
        input?.disconnect();
        audioContext?.close();

        processor = null;
        input = null;
        audioContext = null;
        audioQueue = [];
        isPlaying = false;
    }

    function cleanupSocket() {
        if (socket?.readyState === WebSocket.OPEN) {
            socket.close();
        }
        socket = null;
    }

    // ğŸ§¼ ìœ í‹¸
    function toggleButtons({ start, record, end }) {
        startCallBtn.disabled = !start;
        recordBtn.disabled = !record;
        endCallBtn.disabled = !end;
    }

    function updateStatus(message) {
        statusText.textContent = message;
    }

    // ğŸ“² ì´ë²¤íŠ¸ ë°”ì¸ë”©
    startCallBtn.addEventListener('click', startCall);
    recordBtn.addEventListener('mousedown', startRecording);
    recordBtn.addEventListener('mouseup', stopRecording);
    recordBtn.addEventListener('touchstart', (e) => {
        e.preventDefault(); startRecording();
    });
    recordBtn.addEventListener('touchend', (e) => {
        e.preventDefault(); stopRecording();
    });
    endCallBtn.addEventListener('click', endCall);
</script>
</body>
</html>